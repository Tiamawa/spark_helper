<!DOCTYPE html >
<html>
        <head>
          <title>SparkHelper - com.spark_helper.SparkHelper</title>
          <meta name="description" content="SparkHelper - com.spark helper.SparkHelper" />
          <meta name="keywords" content="SparkHelper com.spark helper.SparkHelper" />
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      <link href="../../lib/template.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css" />
      <script type="text/javascript" src="../../lib/jquery.js" id="jquery-js"></script>
      <script type="text/javascript" src="../../lib/jquery-ui.js"></script>
      <script type="text/javascript" src="../../lib/template.js"></script>
      <script type="text/javascript" src="../../lib/tools.tooltip.js"></script>
      
      <script type="text/javascript">
         if(top === self) {
            var url = '../../index.html';
            var hash = 'com.spark_helper.SparkHelper$';
            var anchor = window.location.hash;
            var anchor_opt = '';
            if (anchor.length >= 1)
              anchor_opt = '@' + anchor.substring(1);
            window.location.href = url + '#' + hash + anchor_opt;
         }
   	  </script>
    
        </head>
        <body class="value">
      <div id="definition">
        <img alt="Object" src="../../lib/object_big.png" />
        <p id="owner"><a href="../package.html" class="extype" name="com">com</a>.<a href="package.html" class="extype" name="com.spark_helper">spark_helper</a></p>
        <h1>SparkHelper</h1><h3><span class="morelinks"><div>Related Doc:
            <a href="package.html" class="extype" name="com.spark_helper">package spark_helper</a>
          </div></span></h3><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      </div>

      <h4 id="signature" class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <span class="name">SparkHelper</span><span class="result"> extends <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      </h4>
      
          <div id="comment" class="fullcommenttop"><div class="comment cmt"><p>A facility to deal with RDD/file manipulations based on the Spark API.</p><p>The goal is to remove the maximum of highly used low-level code from your
spark job and replace it with methods fully tested whose name is
self-explanatory/readable.</p><p>A few exemples:</p><pre><span class="cmt">// Same as SparkContext.saveAsTextFile, but the result is a single file:</span>
SparkHelper.saveAsSingleTextFile(myOutputRDD, <span class="lit">"/my/output/file/path.txt"</span>)
<span class="cmt">// Same as SparkContext.textFile, but instead of reading one record per line,</span>
<span class="cmt">// it reads records spread over several lines:</span>
SparkHelper.textFileWithDelimiter(<span class="lit">"/my/input/folder/path"</span>, sparkContext, <span class="lit">"---\n"</span>)</pre><p>Source <a href="https://github.com/xavierguihot/spark_helper/blob/master/src
/main/scala/com/spark_helper/SparkHelper.scala">SparkHelper</a>
</p></div><dl class="attributes block"> <dt>Since</dt><dd><p>2017-02</p></dd></dl><div class="toggleContainer block">
          <span class="toggle">Linear Supertypes</span>
          <div class="superTypes hiddenContent"><span class="extype" name="scala.Serializable">Serializable</span>, <span class="extype" name="java.io.Serializable">Serializable</span>, <span class="extype" name="scala.AnyRef">AnyRef</span>, <span class="extype" name="scala.Any">Any</span></div>
        </div></div>
        

      <div id="mbrsel">
        <div id="textfilter"><span class="pre"></span><span class="input"><input id="mbrsel-input" type="text" accesskey="/" /></span><span class="post"></span></div>
        <div id="order">
              <span class="filtertype">Ordering</span>
              <ol>
                
                <li class="alpha in"><span>Alphabetic</span></li>
                <li class="inherit out"><span>By Inheritance</span></li>
              </ol>
            </div>
        <div id="ancestors">
                <span class="filtertype">Inherited<br />
                </span>
                <ol id="linearization">
                  <li class="in" name="com.spark_helper.SparkHelper"><span>SparkHelper</span></li><li class="in" name="scala.Serializable"><span>Serializable</span></li><li class="in" name="java.io.Serializable"><span>Serializable</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li>
                </ol>
              </div><div id="ancestors">
            <span class="filtertype"></span>
            <ol>
              <li class="hideall out"><span>Hide All</span></li>
              <li class="showall in"><span>Show All</span></li>
            </ol>
          </div>
        <div id="visbl">
            <span class="filtertype">Visibility</span>
            <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
          </div>
      </div>

      <div id="template">
        <div id="allMembers">
        

        

        

        <div id="values" class="values members">
              <h3>Value Members</h3>
              <ol><li name="scala.AnyRef#!=" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="!=(x$1:Any):Boolean"></a>
      <a id="!=(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $bang$eq" class="name">!=</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@!=(x$1:Any):Boolean" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef###" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="##():Int"></a>
      <a id="##():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $hash$hash" class="name">##</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@##():Int" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#==" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="==(x$1:Any):Boolean"></a>
      <a id="==(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span title="gt4s: $eq$eq" class="name">==</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@==(x$1:Any):Boolean" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.Any#asInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="asInstanceOf[T0]:T0"></a>
      <a id="asInstanceOf[T0]:T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Any.asInstanceOf.T0">T0</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@asInstanceOf[T0]:T0" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="scala.AnyRef#clone" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="clone():Object"></a>
      <a id="clone():AnyRef"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">clone</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.AnyRef">AnyRef</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@clone():Object" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.CloneNotSupportedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="com.spark_helper.SparkHelper#decreaseCoalescence" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="decreaseCoalescence(highCoalescenceLevelFolder:String,lowerCoalescenceLevelFolder:String,finalCoalescenceLevel:Int,sparkContext:org.apache.spark.SparkContext,compressionCodec:Class[_&lt;:org.apache.hadoop.io.compress.CompressionCodec]):Unit"></a>
      <a id="decreaseCoalescence(String,String,Int,SparkContext,Class[_&lt;:CompressionCodec]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">decreaseCoalescence</span><span class="params">(<span name="highCoalescenceLevelFolder">highCoalescenceLevelFolder: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="lowerCoalescenceLevelFolder">lowerCoalescenceLevelFolder: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="finalCoalescenceLevel">finalCoalescenceLevel: <span class="extype" name="scala.Int">Int</span></span>, <span name="sparkContext">sparkContext: <span class="extype" name="org.apache.spark.SparkContext">SparkContext</span></span>, <span name="compressionCodec">compressionCodec: <span class="extype" name="scala.Predef.Class">Class</span>[_ &lt;: <span class="extype" name="org.apache.hadoop.io.compress.CompressionCodec">CompressionCodec</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@decreaseCoalescence(highCoalescenceLevelFolder:String,lowerCoalescenceLevelFolder:String,finalCoalescenceLevel:Int,sparkContext:org.apache.spark.SparkContext,compressionCodec:Class[_&lt;:org.apache.hadoop.io.compress.CompressionCodec]):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Decreases the nbr of partitions of a folder.</p><div class="fullcomment"><div class="comment cmt"><p>Decreases the nbr of partitions of a folder.</p><p>This is often handy when the last step of your job needs to run on
thousands of files, but you want to store your final output on let's say
only 300 files.</p><p>It's like a FileUtil.copyMerge, but the merging produces more than one
file.</p><p>Be aware that this methods deletes the provided input folder.</p><pre>SparkHelper.decreaseCoalescence(
	<span class="lit">"/folder/path/with/2000/files"</span>, <span class="lit">"/produced/folder/path/with/only/300/files"</span>, <span class="num">300</span>, sparkContext, classOf[BZip2Codec]
)</pre></div><dl class="paramcmts block"><dt class="param">highCoalescenceLevelFolder</dt><dd class="cmt"><p>the folder which contains 10000 files</p></dd><dt class="param">lowerCoalescenceLevelFolder</dt><dd class="cmt"><p>the folder which will contain the
same data as highCoalescenceLevelFolder but spread on only 300 files (
where 300 is the finalCoalescenceLevel parameter).</p></dd><dt class="param">finalCoalescenceLevel</dt><dd class="cmt"><p>the nbr of files within the folder at the
end of this method.</p></dd><dt class="param">sparkContext</dt><dd class="cmt"><p>the SparkContext</p></dd><dt class="param">compressionCodec</dt><dd class="cmt"><p>the type of compression to use (for instance
classOf[BZip2Codec] or classOf[GzipCodec]))</p></dd></dl></div>
    </li><li name="com.spark_helper.SparkHelper#decreaseCoalescence" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="decreaseCoalescence(highCoalescenceLevelFolder:String,lowerCoalescenceLevelFolder:String,finalCoalescenceLevel:Int,sparkContext:org.apache.spark.SparkContext):Unit"></a>
      <a id="decreaseCoalescence(String,String,Int,SparkContext):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">decreaseCoalescence</span><span class="params">(<span name="highCoalescenceLevelFolder">highCoalescenceLevelFolder: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="lowerCoalescenceLevelFolder">lowerCoalescenceLevelFolder: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="finalCoalescenceLevel">finalCoalescenceLevel: <span class="extype" name="scala.Int">Int</span></span>, <span name="sparkContext">sparkContext: <span class="extype" name="org.apache.spark.SparkContext">SparkContext</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@decreaseCoalescence(highCoalescenceLevelFolder:String,lowerCoalescenceLevelFolder:String,finalCoalescenceLevel:Int,sparkContext:org.apache.spark.SparkContext):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Decreases the nbr of partitions of a folder.</p><div class="fullcomment"><div class="comment cmt"><p>Decreases the nbr of partitions of a folder.</p><p>This is often handy when the last step of your job needs to run on
thousands of files, but you want to store your final output on let's say
only 300 files.</p><p>It's like a FileUtil.copyMerge, but the merging produces more than one
file.</p><p>Be aware that this methods deletes the provided input folder.</p><pre>SparkHelper.decreaseCoalescence(
	<span class="lit">"/folder/path/with/2000/files"</span>, <span class="lit">"/produced/folder/path/with/only/300/files"</span>, <span class="num">300</span>, sparkContext
)</pre></div><dl class="paramcmts block"><dt class="param">highCoalescenceLevelFolder</dt><dd class="cmt"><p>the folder which contains 10000 files</p></dd><dt class="param">lowerCoalescenceLevelFolder</dt><dd class="cmt"><p>the folder which will contain the
same data as highCoalescenceLevelFolder but spread on only 300 files (
where 300 is the finalCoalescenceLevel parameter).</p></dd><dt class="param">finalCoalescenceLevel</dt><dd class="cmt"><p>the nbr of files within the folder at the
end of this method.</p></dd><dt class="param">sparkContext</dt><dd class="cmt"><p>the SparkContext</p></dd></dl></div>
    </li><li name="scala.AnyRef#eq" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="eq(x$1:AnyRef):Boolean"></a>
      <a id="eq(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">eq</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@eq(x$1:AnyRef):Boolean" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#equals" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="equals(x$1:Any):Boolean"></a>
      <a id="equals(Any):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Any">Any</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@equals(x$1:Any):Boolean" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#finalize" visbl="prt" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="finalize():Unit"></a>
      <a id="finalize():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">finalize</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@finalize():Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Attributes</dt><dd>protected[<a href="../../java$lang.html" class="extype" name="java.lang">java.lang</a>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="symbol">classOf[java.lang.Throwable]</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#getClass" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="getClass():Class[_]"></a>
      <a id="getClass():Class[_]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">getClass</span><span class="params">()</span><span class="result">: <span class="extype" name="java.lang.Class">Class</span>[_]</span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@getClass():Class[_]" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#hashCode" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="hashCode():Int"></a>
      <a id="hashCode():Int"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">hashCode</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Int">Int</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@hashCode():Int" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.Any#isInstanceOf" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="isInstanceOf[T0]:Boolean"></a>
      <a id="isInstanceOf[T0]:Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@isInstanceOf[T0]:Boolean" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>Any</dd></dl></div>
    </li><li name="scala.AnyRef#ne" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ne(x$1:AnyRef):Boolean"></a>
      <a id="ne(AnyRef):Boolean"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">ne</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.AnyRef">AnyRef</span></span>)</span><span class="result">: <span class="extype" name="scala.Boolean">Boolean</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@ne(x$1:AnyRef):Boolean" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notify" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notify():Unit"></a>
      <a id="notify():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notify</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@notify():Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="scala.AnyRef#notifyAll" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="notifyAll():Unit"></a>
      <a id="notifyAll():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@notifyAll():Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="com.spark_helper.SparkHelper#saveAsSingleTextFile" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsSingleTextFile(outputRDD:org.apache.spark.rdd.RDD[String],outputFile:String,workingFolder:String,compressionCodec:Class[_&lt;:org.apache.hadoop.io.compress.CompressionCodec]):Unit"></a>
      <a id="saveAsSingleTextFile(RDD[String],String,String,Class[_&lt;:CompressionCodec]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsSingleTextFile</span><span class="params">(<span name="outputRDD">outputRDD: <span class="extype" name="org.apache.spark.rdd.RDD">RDD</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="outputFile">outputFile: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="workingFolder">workingFolder: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="compressionCodec">compressionCodec: <span class="extype" name="scala.Predef.Class">Class</span>[_ &lt;: <span class="extype" name="org.apache.hadoop.io.compress.CompressionCodec">CompressionCodec</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@saveAsSingleTextFile(outputRDD:org.apache.spark.rdd.RDD[String],outputFile:String,workingFolder:String,compressionCodec:Class[_&lt;:org.apache.hadoop.io.compress.CompressionCodec]):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Saves an RDD in exactly one file.</p><div class="fullcomment"><div class="comment cmt"><p>Saves an RDD in exactly one file.</p><p>Allows one to save an RDD in one file, while keeping the processing
parallelized.</p><p>This variant of saveAsSingleTextFile performs the storage in a temporary
folder instead of directly in the final output folder. This way the
risks of having corrupted files in the real output folder due to cluster
interruptions is minimized.</p><pre>SparkHelper.saveAsSingleTextFile(myRddToStore, <span class="lit">"/my/file/path.txt"</span>, <span class="lit">"/my/working/folder/path"</span>, classOf[BZip2Codec])</pre></div><dl class="paramcmts block"><dt class="param">outputRDD</dt><dd class="cmt"><p>the RDD of strings to store in one file</p></dd><dt class="param">outputFile</dt><dd class="cmt"><p>the path of the produced file</p></dd><dt class="param">workingFolder</dt><dd class="cmt"><p>the path where file manipulations will temporarily
happen.</p></dd><dt class="param">compressionCodec</dt><dd class="cmt"><p>the type of compression to use (for instance
classOf[BZip2Codec] or classOf[GzipCodec]))</p></dd></dl></div>
    </li><li name="com.spark_helper.SparkHelper#saveAsSingleTextFile" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsSingleTextFile(outputRDD:org.apache.spark.rdd.RDD[String],outputFile:String,workingFolder:String):Unit"></a>
      <a id="saveAsSingleTextFile(RDD[String],String,String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsSingleTextFile</span><span class="params">(<span name="outputRDD">outputRDD: <span class="extype" name="org.apache.spark.rdd.RDD">RDD</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="outputFile">outputFile: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="workingFolder">workingFolder: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@saveAsSingleTextFile(outputRDD:org.apache.spark.rdd.RDD[String],outputFile:String,workingFolder:String):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Saves an RDD in exactly one file.</p><div class="fullcomment"><div class="comment cmt"><p>Saves an RDD in exactly one file.</p><p>Allows one to save an RDD in one file, while keeping the processing
parallelized.</p><p>This variant of saveAsSingleTextFile performs the storage in a temporary
folder instead of directly in the final output folder. This way the
risks of having corrupted files in the real output folder due to cluster
interruptions is minimized.</p><pre>SparkHelper.saveAsSingleTextFile(myRddToStore, <span class="lit">"/my/file/path.txt"</span>, <span class="lit">"/my/working/folder/path"</span>)</pre></div><dl class="paramcmts block"><dt class="param">outputRDD</dt><dd class="cmt"><p>the RDD of strings to store in one file</p></dd><dt class="param">outputFile</dt><dd class="cmt"><p>the path of the produced file</p></dd><dt class="param">workingFolder</dt><dd class="cmt"><p>the path where file manipulations will temporarily
happen.</p></dd></dl></div>
    </li><li name="com.spark_helper.SparkHelper#saveAsSingleTextFile" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsSingleTextFile(outputRDD:org.apache.spark.rdd.RDD[String],outputFile:String,compressionCodec:Class[_&lt;:org.apache.hadoop.io.compress.CompressionCodec]):Unit"></a>
      <a id="saveAsSingleTextFile(RDD[String],String,Class[_&lt;:CompressionCodec]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsSingleTextFile</span><span class="params">(<span name="outputRDD">outputRDD: <span class="extype" name="org.apache.spark.rdd.RDD">RDD</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="outputFile">outputFile: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="compressionCodec">compressionCodec: <span class="extype" name="scala.Predef.Class">Class</span>[_ &lt;: <span class="extype" name="org.apache.hadoop.io.compress.CompressionCodec">CompressionCodec</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@saveAsSingleTextFile(outputRDD:org.apache.spark.rdd.RDD[String],outputFile:String,compressionCodec:Class[_&lt;:org.apache.hadoop.io.compress.CompressionCodec]):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Saves an RDD in exactly one file.</p><div class="fullcomment"><div class="comment cmt"><p>Saves an RDD in exactly one file.</p><p>Allows one to save an RDD in one file, while keeping the processing
parallelized.</p><pre>SparkHelper.saveAsSingleTextFile(myRddToStore, <span class="lit">"/my/file/path.txt"</span>, classOf[BZip2Codec])</pre></div><dl class="paramcmts block"><dt class="param">outputRDD</dt><dd class="cmt"><p>the RDD of strings to store in one file</p></dd><dt class="param">outputFile</dt><dd class="cmt"><p>the path of the produced file</p></dd><dt class="param">compressionCodec</dt><dd class="cmt"><p>the type of compression to use (for instance
classOf[BZip2Codec] or classOf[GzipCodec]))</p></dd></dl></div>
    </li><li name="com.spark_helper.SparkHelper#saveAsSingleTextFile" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsSingleTextFile(outputRDD:org.apache.spark.rdd.RDD[String],outputFile:String):Unit"></a>
      <a id="saveAsSingleTextFile(RDD[String],String):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsSingleTextFile</span><span class="params">(<span name="outputRDD">outputRDD: <span class="extype" name="org.apache.spark.rdd.RDD">RDD</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="outputFile">outputFile: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@saveAsSingleTextFile(outputRDD:org.apache.spark.rdd.RDD[String],outputFile:String):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Saves an RDD in exactly one file.</p><div class="fullcomment"><div class="comment cmt"><p>Saves an RDD in exactly one file.</p><p>Allows one to save an RDD in one file, while keeping the processing
parallelized.</p><pre>SparkHelper.saveAsSingleTextFile(myRddToStore, <span class="lit">"/my/file/path.txt"</span>)</pre></div><dl class="paramcmts block"><dt class="param">outputRDD</dt><dd class="cmt"><p>the RDD of strings to store in one file</p></dd><dt class="param">outputFile</dt><dd class="cmt"><p>the path of the produced file</p></dd></dl></div>
    </li><li name="com.spark_helper.SparkHelper#saveAsTextFileAndCoalesce" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsTextFileAndCoalesce(outputRDD:org.apache.spark.rdd.RDD[String],outputFolder:String,finalCoalescenceLevel:Int,compressionCodec:Class[_&lt;:org.apache.hadoop.io.compress.CompressionCodec]):Unit"></a>
      <a id="saveAsTextFileAndCoalesce(RDD[String],String,Int,Class[_&lt;:CompressionCodec]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsTextFileAndCoalesce</span><span class="params">(<span name="outputRDD">outputRDD: <span class="extype" name="org.apache.spark.rdd.RDD">RDD</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="outputFolder">outputFolder: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="finalCoalescenceLevel">finalCoalescenceLevel: <span class="extype" name="scala.Int">Int</span></span>, <span name="compressionCodec">compressionCodec: <span class="extype" name="scala.Predef.Class">Class</span>[_ &lt;: <span class="extype" name="org.apache.hadoop.io.compress.CompressionCodec">CompressionCodec</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@saveAsTextFileAndCoalesce(outputRDD:org.apache.spark.rdd.RDD[String],outputFolder:String,finalCoalescenceLevel:Int,compressionCodec:Class[_&lt;:org.apache.hadoop.io.compress.CompressionCodec]):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Saves as text file, but by decreasing the nbr of partitions of the output.</p><div class="fullcomment"><div class="comment cmt"><p>Saves as text file, but by decreasing the nbr of partitions of the output.</p><p>Same as decreaseCoalescence, but the storage of the RDD in an
intermediate folder is included.</p><p>This still makes the processing parallelized, but the output is
coalesced.</p><pre>SparkHelper.saveAsTextFileAndCoalesce(myRddToStore, <span class="lit">"/produced/folder/path/with/only/300/files"</span>, <span class="num">300</span>, classOf[BZip2Codec])</pre></div><dl class="paramcmts block"><dt class="param">outputRDD</dt><dd class="cmt"><p>the RDD to store, processed for instance on 10000 tasks
(which would thus be stored as 10000 files).</p></dd><dt class="param">outputFolder</dt><dd class="cmt"><p>the folder where will finally be stored the RDD but
spread on only 300 files (where 300 is the value of the
finalCoalescenceLevel parameter).</p></dd><dt class="param">finalCoalescenceLevel</dt><dd class="cmt"><p>the nbr of files within the folder at the
end of this method.</p></dd><dt class="param">compressionCodec</dt><dd class="cmt"><p>the type of compression to use (for instance
classOf[BZip2Codec] or classOf[GzipCodec]))</p></dd></dl></div>
    </li><li name="com.spark_helper.SparkHelper#saveAsTextFileAndCoalesce" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsTextFileAndCoalesce(outputRDD:org.apache.spark.rdd.RDD[String],outputFolder:String,finalCoalescenceLevel:Int):Unit"></a>
      <a id="saveAsTextFileAndCoalesce(RDD[String],String,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsTextFileAndCoalesce</span><span class="params">(<span name="outputRDD">outputRDD: <span class="extype" name="org.apache.spark.rdd.RDD">RDD</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>, <span name="outputFolder">outputFolder: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="finalCoalescenceLevel">finalCoalescenceLevel: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@saveAsTextFileAndCoalesce(outputRDD:org.apache.spark.rdd.RDD[String],outputFolder:String,finalCoalescenceLevel:Int):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Saves as text file, but by decreasing the nbr of partitions of the output.</p><div class="fullcomment"><div class="comment cmt"><p>Saves as text file, but by decreasing the nbr of partitions of the output.</p><p>Same as decreaseCoalescence, but the storage of the RDD in an
intermediate folder is included.</p><p>This still makes the processing parallelized, but the output is
coalesced.</p><pre>SparkHelper.saveAsTextFileAndCoalesce(myRddToStore, <span class="lit">"/produced/folder/path/with/only/300/files"</span>, <span class="num">300</span>)</pre></div><dl class="paramcmts block"><dt class="param">outputRDD</dt><dd class="cmt"><p>the RDD to store, processed for instance on 10000 tasks
(which would thus be stored as 10000 files).</p></dd><dt class="param">outputFolder</dt><dd class="cmt"><p>the folder where will finally be stored the RDD but
spread on only 300 files (where 300 is the value of the
finalCoalescenceLevel parameter).</p></dd><dt class="param">finalCoalescenceLevel</dt><dd class="cmt"><p>the nbr of files within the folder at the
end of this method.</p></dd></dl></div>
    </li><li name="com.spark_helper.SparkHelper#saveAsTextFileByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsTextFileByKey(keyValueRDD:org.apache.spark.rdd.RDD[(String,String)],outputFolder:String,keyNbr:Int,compressionCodec:Class[_&lt;:org.apache.hadoop.io.compress.CompressionCodec]):Unit"></a>
      <a id="saveAsTextFileByKey(RDD[(String,String)],String,Int,Class[_&lt;:CompressionCodec]):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsTextFileByKey</span><span class="params">(<span name="keyValueRDD">keyValueRDD: <span class="extype" name="org.apache.spark.rdd.RDD">RDD</span>[(<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>)]</span>, <span name="outputFolder">outputFolder: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="keyNbr">keyNbr: <span class="extype" name="scala.Int">Int</span></span>, <span name="compressionCodec">compressionCodec: <span class="extype" name="scala.Predef.Class">Class</span>[_ &lt;: <span class="extype" name="org.apache.hadoop.io.compress.CompressionCodec">CompressionCodec</span>]</span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@saveAsTextFileByKey(keyValueRDD:org.apache.spark.rdd.RDD[(String,String)],outputFolder:String,keyNbr:Int,compressionCodec:Class[_&lt;:org.apache.hadoop.io.compress.CompressionCodec]):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Saves and repartitions a key/value RDD on files whose name is the key.</p><div class="fullcomment"><div class="comment cmt"><p>Saves and repartitions a key/value RDD on files whose name is the key.</p><p>Within the provided outputFolder, will be one file per key in your
keyValueRDD. And within a file for a given key are only values for this
key.</p><p>You need to know the nbr of keys beforehand (in general you use this to
split your dataset in subsets, or to output one file per client, so you
know how many keys you have). So you need to put as keyNbr the exact nbr
of keys you'll have.</p><p>This is not scalable. This shouldn't be considered for any data flow
with normal or big volumes.</p><pre>SparkHelper.saveAsTextFileByKey(myKeyValueRddToStore, <span class="lit">"/my/output/folder/path"</span>, <span class="num">12</span>, classOf[BZip2Codec])</pre></div><dl class="paramcmts block"><dt class="param">keyValueRDD</dt><dd class="cmt"><p>the key/value RDD</p></dd><dt class="param">outputFolder</dt><dd class="cmt"><p>the foldder where will be storrred key files</p></dd><dt class="param">keyNbr</dt><dd class="cmt"><p>the nbr of expected keys (which is the nbr of outputed
files).</p></dd><dt class="param">compressionCodec</dt><dd class="cmt"><p>the type of compression to use (for instance
classOf[BZip2Codec] or classOf[GzipCodec]))</p></dd></dl></div>
    </li><li name="com.spark_helper.SparkHelper#saveAsTextFileByKey" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="saveAsTextFileByKey(keyValueRDD:org.apache.spark.rdd.RDD[(String,String)],outputFolder:String,keyNbr:Int):Unit"></a>
      <a id="saveAsTextFileByKey(RDD[(String,String)],String,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">saveAsTextFileByKey</span><span class="params">(<span name="keyValueRDD">keyValueRDD: <span class="extype" name="org.apache.spark.rdd.RDD">RDD</span>[(<span class="extype" name="scala.Predef.String">String</span>, <span class="extype" name="scala.Predef.String">String</span>)]</span>, <span name="outputFolder">outputFolder: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="keyNbr">keyNbr: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@saveAsTextFileByKey(keyValueRDD:org.apache.spark.rdd.RDD[(String,String)],outputFolder:String,keyNbr:Int):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Saves and repartitions a key/value RDD on files whose name is the key.</p><div class="fullcomment"><div class="comment cmt"><p>Saves and repartitions a key/value RDD on files whose name is the key.</p><p>Within the provided outputFolder, will be one file per key in your
keyValueRDD. And within a file for a given key are only values for this
key.</p><p>You need to know the nbr of keys beforehand (in general you use this to
split your dataset in subsets, or to output one file per client, so you
know how many keys you have). So you need to put as keyNbr the exact nbr
of keys you'll have.</p><p>This is not scalable. This shouldn't be considered for any data flow
with normal or big volumes.</p><pre>SparkHelper.saveAsTextFileByKey(myKeyValueRddToStore, <span class="lit">"/my/output/folder/path"</span>, <span class="num">12</span>)</pre></div><dl class="paramcmts block"><dt class="param">keyValueRDD</dt><dd class="cmt"><p>the key/value RDD</p></dd><dt class="param">outputFolder</dt><dd class="cmt"><p>the foldder where will be storrred key files</p></dd><dt class="param">keyNbr</dt><dd class="cmt"><p>the nbr of expected keys (which is the nbr of outputed
files).</p></dd></dl></div>
    </li><li name="scala.AnyRef#synchronized" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="synchronized[T0](x$1:=&gt;T0):T0"></a>
      <a id="synchronized[T0](⇒T0):T0"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: ⇒ <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>)</span><span class="result">: <span class="extype" name="java.lang.AnyRef.synchronized.T0">T0</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@synchronized[T0](x$1:=&gt;T0):T0" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd></dl></div>
    </li><li name="com.spark_helper.SparkHelper#textFileWithDelimiter" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="textFileWithDelimiter(hdfsPath:String,sparkContext:org.apache.spark.SparkContext,delimiter:String):org.apache.spark.rdd.RDD[String]"></a>
      <a id="textFileWithDelimiter(String,SparkContext,String):RDD[String]"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">textFileWithDelimiter</span><span class="params">(<span name="hdfsPath">hdfsPath: <span class="extype" name="scala.Predef.String">String</span></span>, <span name="sparkContext">sparkContext: <span class="extype" name="org.apache.spark.SparkContext">SparkContext</span></span>, <span name="delimiter">delimiter: <span class="extype" name="scala.Predef.String">String</span></span>)</span><span class="result">: <span class="extype" name="org.apache.spark.rdd.RDD">RDD</span>[<span class="extype" name="scala.Predef.String">String</span>]</span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@textFileWithDelimiter(hdfsPath:String,sparkContext:org.apache.spark.SparkContext,delimiter:String):org.apache.spark.rdd.RDD[String]" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <p class="shortcomment cmt">Equivalent to sparkContext.textFile(), but for a specific record delimiter.</p><div class="fullcomment"><div class="comment cmt"><p>Equivalent to sparkContext.textFile(), but for a specific record delimiter.</p><p>By default, sparkContext.textFile() will provide one record per line.
But what if the format you want to read considers that one record (one
entity) is stored in more than one line (yml, xml, ...)?</p><p>For instance in order to read a yml file, which is a format for which a
record (a single entity) is spread other several lines, you can modify
the record delimiter with &quot;---\n&quot; instead of &quot;\n&quot;. Same goes when
reading an xml file where a record might be spread over several lines or
worse the whole xml file is one line.</p><pre><span class="cmt">// Let's say data we want to use with Spark looks like this (one record</span>
<span class="cmt">// is a customer, but it's spread over several lines):</span>
&lt;Customers&gt;\n
&lt;Customer&gt;\n
&lt;Address&gt;<span class="num">34</span> thingy street, someplace, sometown&lt;/Address&gt;\n
&lt;/Customer&gt;\n
&lt;Customer&gt;\n
&lt;Address&gt;<span class="num">12</span> thingy street, someplace, sometown&lt;/Address&gt;\n
&lt;/Customer&gt;\n
&lt;/Customers&gt;
<span class="cmt">//Then you can use it this way:</span>
<span class="kw">val</span> computedRecords = HdfsHelper.textFileWithDelimiter(
	<span class="lit">"my/path/to/customers.xml"</span>, sparkContext, &lt;Customer&gt;\n
).collect()
<span class="kw">val</span> expectedRecords = <span class="std">Array</span>(
	&lt;Customers&gt;\n,
	(
		&lt;Address&gt;<span class="num">34</span> thingy street, someplace, sometown&lt;/Address&gt;\n +
		&lt;/Customer&gt;\n
	),
	(
		&lt;Address&gt;<span class="num">12</span> thingy street, someplace, sometown&lt;/Address&gt;\n +
		&lt;/Customer&gt;\n +
		&lt;/Customers&gt;
	)
)
assert(computedRecords == expectedRecords)</pre></div><dl class="paramcmts block"><dt class="param">hdfsPath</dt><dd class="cmt"><p>the path of the file to read (folder or file, '*' works
as well).</p></dd><dt class="param">sparkContext</dt><dd class="cmt"><p>the SparkContext</p></dd><dt class="param">delimiter</dt><dd class="cmt"><p>the specific record delimiter which replaces &quot;\n&quot;</p></dd><dt>returns</dt><dd class="cmt"><p>the RDD of records</p></dd></dl></div>
    </li><li name="scala.AnyRef#toString" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="toString():String"></a>
      <a id="toString():String"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">toString</span><span class="params">()</span><span class="result">: <span class="extype" name="java.lang.String">String</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@toString():String" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait():Unit"></a>
      <a id="wait():Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">()</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@wait():Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long,x$2:Int):Unit"></a>
      <a id="wait(Long,Int):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>, <span name="arg1">arg1: <span class="extype" name="scala.Int">Int</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@wait(x$1:Long,x$2:Int):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li><li name="scala.AnyRef#wait" visbl="pub" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="wait(x$1:Long):Unit"></a>
      <a id="wait(Long):Unit"></a>
      <h4 class="signature">
      <span class="modifier_kind">
        <span class="modifier">final </span>
        <span class="kind">def</span>
      </span>
      <span class="symbol">
        <span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span class="extype" name="scala.Long">Long</span></span>)</span><span class="result">: <span class="extype" name="scala.Unit">Unit</span></span>
      </span>
      </h4><span class="permalink">
      <a href="../../index.html#com.spark_helper.SparkHelper$@wait(x$1:Long):Unit" title="Permalink" target="_top">
        <img src="../../lib/permalink.png" alt="Permalink" />
      </a>
    </span>
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd>
                <span class="name">@throws</span><span class="args">(<span>
      
      <span class="defval" name="classOf[java.lang.InterruptedException]">...</span>
    </span>)</span>
              
        </dd></dl></div>
    </li></ol>
            </div>

        

        
        </div>

        <div id="inheritedMembers">
        <div class="parent" name="scala.Serializable">
              <h3>Inherited from <span class="extype" name="scala.Serializable">Serializable</span></h3>
            </div><div class="parent" name="java.io.Serializable">
              <h3>Inherited from <span class="extype" name="java.io.Serializable">Serializable</span></h3>
            </div><div class="parent" name="scala.AnyRef">
              <h3>Inherited from <span class="extype" name="scala.AnyRef">AnyRef</span></h3>
            </div><div class="parent" name="scala.Any">
              <h3>Inherited from <span class="extype" name="scala.Any">Any</span></h3>
            </div>
        
        </div>

        <div id="groupedMembers">
        <div class="group" name="Ungrouped">
              <h3>Ungrouped</h3>
              
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>


    </body>
      </html>
